Заметки о Docker
================

# Оглавление

1. <h3>[Введение](#Введение)</h3>

    - [Установка](#Установка)
    - [Общие сведения](#Общие-сведения)
    - [Полезные команды](#Полезные-команды)
    - [Пользователь в Docker](#Пользователь-в-Docker)
    - [Оптимизация размера образа](#Оптимизация-размера-образа)
    
2. <h3>[Внутренние устройство](#Внутренние-устройство)</h3>

    - [Обзор контейнеризации (что это, чем отличается от виртуализации, уровень безопасности)](#Обзор-контейнеризации-(что-это,-чем-отличается-от-виртуализации,-уровень-безопасности))
    - [Устройство докер образов](#Устройство-докер-образов)

3. <h3>[Примеры использования docker](#Примеры-использования-docker)</h3>
    
    - [Запуск PostgreSQL](#Запуск-PostgreSQL)
    - [Запуск RabbitMQ](#Запуск-RabbitMQ)
    - [Запуск простого web-приложения в docker](#Запуск-простого-web-приложения-в-docker)

5. <h3>[docker-compose](#docker-compose)</h3>
    
    - [Применение DRY к docker-compose.yml](#Применение-DRY-к-docker-compose.yml)
    - [Работа с секретами](#Работа-с-секретами)
  

<a name='Введение'></a>
## Введение


<a name='Установка'></a>
### Установка

**Установка на mac os**

Для того, чтобы установить docker на mac os, необходимо:

- иметь установленный brew [инструкция по установке](../macos/macos-notes-index.md#Установка-brew)
- добавить в brew реппозиторий cask 
  ```bash
  brew tap caskroom/cask
  ```
- при помощи brew установить docker
  ```bash
  brew cask install docker
  ```
- отключить SIP (System Integrity Protection). Если это не сделать есть 
  большая вероятность получить проблемы. Точно известно, что если не отключить
  SIP то при определенных обстоятельствах будет возникать ошибка `Cannot start 
  service db: b'Mounts denied: EOF'`.
  Инструкцию по отключению sip можно прочитать [тут](../macos/macos-notes-index.md#Отключение-SIP).


<a name='Общие-сведения'></a>
### Общие сведения

- [Понимая Docker | habr](https://habr.com/ru/post/253877/) - общая теория
- [Основы Docker за Х часов и Y дней | habr](https://habr.com/ru/post/337306/) - 
хорошо описана теория с простыми примерами
- [Quickstart: Compose and Django](https://docs.docker.com/compose/django/) -
простой и наглядный пример развертывания django и postgresql при помощи 
docker compose


<a name='Полезные-команды'></a>
### Полезные команды

**Удаление контейнеров/образов**

- `docker rm -vf $(docker ps -a -q)` - удаляет все контейнеры
- `docker rmi -f $(docker images -a -q)` - удаляет все образы
- `docker system prune` - удаляет все не используемые containers, networks, 
  images и опционально volumes
- `docker system prune -a` - удаляет все containers, networks, images и 
  опционально volumes
- `docker volume prune` - удаление всех volume
- `docker-compose down -v` - останавливает containers и удаляет containers, 
  networks, volumes, и images
  
**Обновление контейнеров без остановки**

- `docker-compose up --build -d` - пересобирает образы всех сервисов и потом 
    запускает их (полезно, если на стенде нужно накатить обновления)
- `docker-compose up --build -d app` - пересобирает образ сервиса `app` и потом 
    запускает обновленную версию сервиса (полезно, если на стенде нужно 
    накатить обновления)

**Остановка контейнеров**

- `docker stop $(docker ps -a -q)` - остановка всех контейнеров



<a name='Пользователь-в-Docker'></a>
### Пользователь в Docker

Все процессы в контейнере будут работать из-под пользователя root, если 
специальным образом его не указать. Это кажется очень удобно, ведь у этого 
пользователя нет никаких ограничений. Именно поэтому работать под рутом 
неправильно с точки зрения безопасности. Если на локальном компьютере никто 
в здравом уме не работает с рутовыми правами, то многие запускают процессы 
под рутом в контейнерах.

Всегда есть баги, которые позволят зловреду выбраться из контейнера и попасть 
на хостовый компьютер. Предполагая худшее, мы должны обеспечить запуск 
процессов внутри контейнера от пользователя, который не имеет никаких прав 
на хостовой машине.

Для того, чтобы создать пользователя в дистрибутиве alpine необходимо выполнить:

```
RUN addgroup app_user && adduser -G app_user -s /bin/sh -D app_user
```

В debian подобных дистрибутивах это можно сделать так:

```
RUN groupadd app_user && \
    useradd --gid app_user --shell /bin/bash --create-home app_user
```

После этого, чтобы сменить текущего пользователя необходимо прописать в 
Dockerfile 
```
USER app_user
```

После этого, все запускаемые процессы будут выпоняться от имени `app_user`.

Использованные материалы:

- [Пользователь в Docker](https://habr.com/ru/post/448480/)


<a name='Оптимизация-размера-образа'></a>
### Оптимизация размера образа

Презентация с рассказом как можно уменьшить размер образа за счет того, что в 
конечном образе не будет dev зависимостей [Александр Кошелев, Яндекс «Сборка Docker образов без build зависимостей»](https://youtu.be/2fU0SN4UBY0), [Копия](https://cloud.mail.ru/public/4CyV/39hXkytCv)



<a name='Внутренние-устройство'></a>
## Внутренние устройство


<a name='Обзор-контейнеризации-(что-это,-чем-отличается-от-виртуализации,-уровень-безопасности)'></a>
### Обзор контейнеризации (что это, чем отличается от виртуализации, уровень безопасности)

**Что такое контейнеры**

Контейнеры — это современный способ упаковки, совместного использования и 
развертывания приложения. В отличие от монолитного приложения, в котором все 
функции упакованы в одну программу, контейнерные приложения или микросервисы 
предназначены для целенаправленного узкого использования и специализируются 
только на одной задаче.

Контейнер включает в себя все зависимости (например, пакеты, библиотеки и 
двоичные файлы), которые необходимы приложению для выполнения своей конкретной 
задачи. В результате, контейнеризованные приложения не зависят от платформы и 
могут работать в любой операционной системе независимо от ее версии или 
установленных пакетов. Это удобство избавляет разработчиков от огромного куска 
работы по адаптации разных версий программного обеспечения для разных платформ 
или клиентов. Хотя концептуально это не совсем точно, многим людям нравится 
думать о контейнерах как об «облегченных виртуальных машинах». 

Когда контейнер развертывается на хосте, ресурсы каждого контейнера, такие как
его файловая система, процесс и сетевой стек, помещаются в фактически 
изолированную среду, к которой другие контейнеры не могут получить доступ. Эта 
архитектура позволяет одновременно запускать сотни и тысячи контейнеров в одном
кластере, а каждое приложение (или микросервис) можно потом легко 
масштабировать путем репликации бо́льшего количества экземпляров.

**Как работает контейниризация**

Контейнеризация основана на двух ключевых «строительных блоках»:
пространстве имен Linux и контрольных группах Linux (cgroups). 

Пространство имен создает практически изолированное пользовательское 
пространство и предоставляет приложению выделенные системные ресурсы, такие 
как файловая система, сетевой стек, идентификатор процесса и идентификатор 
пользователя. В этом изолированном пользовательском пространстве приложение 
контролирует корневой каталог файловой системы и может запускаться от имени 
root. Это абстрактное пространство позволяет каждому приложению работать 
независимо, не мешая при этом жить другим приложениям на том же хосте. Сейчас 
доступно шесть пространств имен: mount, inter-process communication (ipc), 
UNIX time-sharing system (uts), process id (pid), network и user. Этот список 
предлагается дополнить еще двумя дополнительными пространствами имен: time и 
syslog, но сообщество Linux все еще не определилось с окончательными 
спецификациями. 

Cgroups обеспечивают ограничение аппаратных ресурсов, расстановку приоритетов, 
мониторинг и контроль приложения. В качестве примера аппаратных ресурсов, 
которыми они могут управлять, можно назвать процессор, память, устройство и 
сеть. При объединении пространства имен и cgroups, мы можем безопасно запускать
несколько приложений на одном хосте, причем каждое приложение находится в 
своей изолированной среде — что есть фундаментальное свойство контейнера.

**Различия контейниризация и виртуализации**

Основное же различие между виртуальной машиной (ВМ) и контейнером заключается 
в том, что виртуальная машина — это виртуализация на аппаратном уровне, а 
контейнер — виртуализация на уровне операционной системы. Гипервизор ВМ 
эмулирует аппаратную среду для каждой машины, где уже среда выполнения 
контейнера в свою очередь эмулирует операционную систему для каждого объекта. 
Виртуальные машины совместно используют физическое оборудование хоста, а 
контейнеры — как оборудование, так и ядро ​​ОС. Поскольку контейнеры в целом 
разделяют с хостом большее количество ресурсов, их работа с хранилищем, 
памятью и циклами ЦП намного эффективнее, чем у виртуальной машины. Однако 
недостатком такого общего доступа является проблемы в плоскости информационной 
безопасноти, так как между контейнерами и хостом устанавливается слишком 
большое доверие.

**Уровень изолированности контейнеров, на сколько они безопасны**

В целом, изоляция виртуализированного оборудования создает гораздо более 
прочный периметр безопасности, нежели просто изоляция именного пространства. 
Риск того, что злоумышленник успешно покинет изолированный процесс, намного 
выше, чем шанс успешного выхода за пределы виртуальной машины. Причиной более 
высокого риска выхода за пределы ограниченной среды контейнеров является слабая
изоляция, создаваемая пространством имен и cgroups. Linux реализует их, 
связывая новые поля свойств с каждым процессом. Эти поля в файловой системе 
`/proc` указывают операционной системе хоста, может ли один процесс видеть 
другой, или сколько ресурсов процессора/памяти может использовать какой-то 
конкретный процесс. При просмотре запущенных процессов и потоков из 
родительской ОС (например, команды `top` или `ps`) контейнерный процесс выглядит 
так же, как любой другой. Как правило, традиционные решения, такие как LXC или 
Docker, не считаются полноценно изолированными, поскольку они используют одно 
и то же ядро в рамках одного хоста. Поэтому, не удивительно, что у контейнеров 
имеется достаточное количество уязвимостей. 

Например, CVE-2014-3519, CVE-2016-5195, CVE-2016-9962, CVE-2017-5123 и 
CVE-2019-5736 могут привести получению злоумышленником доступа к данным за 
пределами контейнера. 

Большинство эксплойтов ядра создают вектор для успешной атаки, поскольку 
обычно они выливаются в повышение привилегий и позволяют скомпрометированному 
процессу получить контроль за пределами своего предполагаемого именного 
пространства. Помимо векторов атак в контексте уязвимостей программного 
обеспечения, свою роль может сыграть и неправильная конфигурация. Например 
развертывание образов с чрезмерными привилегиями (`CAP_SYS_ADMIN`, 
привилегированный доступ) или критические точки монтирования 
(`/var/run/docker.sock`), могут привести к утечке. Учитывая эти потенциально 
катастрофические последствия, следует понимать риск, на который вы идете при 
развертывании системы в мультиарендном пространстве или при использовании 
контейнеров для хранения конфиденциальных данных.


Полезные ссылки:

- [Как сделать контейнеры еще более изолированными: обзор контейнерных sandbox-технологий - habr](https://habr.com/ru/company/itsumma/blog/457760/) - описывает
  что из себя преставляет контейнеризация, сраниват ее с виртуализацией и 
  описывает как разные проекты пытаются создать по настоящему изолированный 
  контейнер.
- [Демонстрация уязвимости CVE-2019-5736](https://youtu.be/zvSgTBg_nac?t=1573)
- [Дмитрий Столяров - Проникновение в Docker с примерами - Flant](https://youtu.be/hdVNKmru3LM), 
  [Копия](https://cloud.mail.ru/public/54kB/4wc2c6MMa) - на примерах простых 
  кусков кода описывается, что из себя представляет docker


<a name='Устройство-докер-образов'></a>
### Устройство докер образов

[Digging into Docker layers](https://medium.com/@jessgreb01/digging-into-docker-layers-c22f948ed612)



<a name='Примеры-использования-docker'></a>
## Примеры использования docker


<a name='Запуск-PostgreSQL'></a>
### Запуск PostgreSQL

**Создание дирректории, которая будет хранить файлы PostgreSQL**

Если мы хотим иметь возможность продолжить работу с созданными в контейнере 
базами данных после перезапуска контейнера, то небходимо создать папку, которая 
будет хранить все данные созданные postgres.

```bash
mkdir -p $HOME/docker/volumes/postgres
```

**Запуск Postgres контейнера**

Запустить контейнер postgres, так же просто как выполнить команду `docker run`

```bash
docker run -d \
           --rm \
           --name pg \
           -e "POSTGRES_USER=alex" \
           -e "POSTGRES_PASSWORD=123" \
           -e "POSTGRES_DB=test" \
           -p "5432:5432" \
           -v $HOME/docker/volumes/postgres:/var/lib/postgresql/data \
           postgres
```

В команде выше использовано достаточно много аргументов, давайте разберем их:

- rm: Зставляет докер выполнять удаление контейнера и связанной с ним файловой
системы при выходе. В общем, если есть необходимость запускать много 
контейнеров, которые не должны жить долго, то считается хорошей практикой 
передавать флаг rm команде `docker run` для автоматической очистки дискового 
пространства.
Стоить заметить, что мы всегда можем использовать ключ -v для сохрнения данных
за пределами контейнера.

- name: Уникальное имя контейнера. Мы можем выбирать любые имена, главное они 
не должны повторяться, потому что в системе не может быть 2 контейнера с 
одинаковым именем. Для повтороного использования имени необходимо либо 
передавать флаг rm команде docker run, либо явно удалить контейнер 
`docker rm <container name>`.

- e: Объявляет переменную окружения в docker контейнере. POSTGRES_PASSWORD - 
задает пароль суперпользователя для PostgreSQL. POSTGRES_USER - задает имя
суперпользователя для PostgreSQL. POSTGRES_DB - задает имя базы данных, которая
будет создана.

- d: Указывает, что контейнер должен быть запущен в detached mode (в фоновом 
режиме).

- p: Привязывает порт 5432 с локальной машины, на порт 5432 в docker контейнере.
Этот параметр позволяет приложениям, работающим вне контейнера, подключаться к 
серверу postgres, работающему внутри контейнера.

- v: Монтирует папку $HOME/docker/volumes/postgres расположенную на локальной 
машине, к папке /var/lib/postgresql/ располагающейся внутри контейнера. Это 
гарантирует сохранение данных postgres даже после удаления контейнера.


**Подключение к Postgres**

Теперь, после того как контейнер запущен, подключение к postgres ни чем не 
отличается от подключения к экземпляру postgres расположеному вне docker 
контейнера. Для примера подключение через psql будет выглядеть следующим 
образом:

```bash
psql -h localhost -U alex -d test
``` 

Ссылки:

- [Don’t install Postgres. Docker pull Postgres](https://hackernoon.com/dont-install-postgres-docker-pull-postgres-bee20e200198) - на
основе данной статьи сделана данная заметка
- [How to create User/Database in script for Docker Postgres](https://stackoverflow.com/questions/26598738/how-to-create-user-database-in-script-for-docker-postgres) -
ответ на то как создать пользователя и базу данных в контейнере c postgres
- [Docker контейнер с данными на Postgres для интеграционного тестирования и лёгким расширением | habr](https://habr.com/ru/post/328226/)


<a name='Запуск-RabbitMQ'></a>
### Запуск RabbitMQ

По сути, запуск RabbitMQ аналогичен запуску PostgreSQL, по этому приведу только
основные команды необходимые для запуска RabbitMQ.

**Создание контейнера с RabbitMQ**

```bash
docker run -d \
           --name rabbit \
           -p "4369:4369" \
           -p "5672:5672" \
           -p "15672:15672" \
           -p "25672:25672" \
           -p "35197:35197" \
           -e "RABBITMQ_USE_LONGNAME=true" \
           -e "RABBITMQ_LOGS=/var/log/rabbitmq/rabbit.log" \
           -v $HOME/docker/volumes/rabbit:/var/lib/rabbitmq \
           -v $HOME/docker/volumes/rabbit/logs:/var/log/rabbitmq \
           rabbitmq:3.7.11-management
```

После выполнения данной команды будет создан и запущен контейнер содержащий 
RabbitMQ. 
 
Интерфейс управления доступен по ссылке [ссылке](http://127.0.0.1:15672).

**Остановка контейнера**

```bash
docker stop rabbit
```

**Запуск контейнера после перезагрузки или остановки контейнера**

```bash
docker container start rabbit
```


Полезные ссылки:

- [Настройка кластера RabbitMQ на Docker](https://thewebland.net/development/devops/rabbitmq/nastrojka-klastera-rabbitmq-na-docker/)
- [Microservices & RabbitMQ On Docker](https://dev.to/usamaashraf/microservices--rabbitmq-on-docker-e2f)
- [Docker Hub - rabbitmq](https://hub.docker.com/_/rabbitmq)


<a name='Запуск-простого-web-приложения-в-docker'></a>
### Запуск простого web-приложения в docker

Для того, чтобы показать базовые принципы создания нового docker образа, 
необходимо создать проект с элементарным web приложением:

app.py

```python
from flask import Flask

app = Flask(__name__)


@app.route('/')
def hello_world():
    return 'Hello, World!'


app.run(host='0.0.0.0', port=5000, debug=True)
```

requirements.txt

```
flask==1.0.2
```

Теперь, когда проект создан можно заняться его докеризацией. Первым делом 
необходимо создать файл `Dockerfile`, который будет содержать инструкции
необходимые для сборки docker образа.

Dockerfile

```dockerfile
FROM python:3.7.4-alpine

RUN addgroup app_user && adduser -G app_user -s /bin/sh -D app_user

# requirements.txt копируется отдельно, для того, чтобы если если список
# зависимостей не менялся, то не производилась их повторная установка
COPY requirements.txt /opt/app/
RUN pip3 install -r /opt/app/requirements.txt

COPY app.py /opt/app/
WORKDIR /opt/app/

USER app_user
CMD ["python3", "app.py"]
```

Собираем образ

```bash
docker build -t simple-web-app .
```

Теперь убеждаемся, что образ успешно создался 

```bash
docker images
```

```
REPOSITORY          TAG                 IMAGE ID            CREATED              SIZE
simple-web-app      latest              39e2e3bc092c        About a minute ago   109MB
python              3.7.4-alpine        ac069ebfe1e1        42 hours ago         98.7MB
```

Как видим из вывода команды, образ был создан и имеет ID `39e2e3bc092c`.
Теперь, мы можем запустить его. Сделать это можно при помощи команды:

```bash
docker run -p 5000:5000 simple-web-app
```

Данная команда запускает образ simple-web-app и связывает 5000 порт локальной 
машины с 5000 портом контейнера, который будет создан в результате запуска 
образа. Если необходимо запустить контейнер в фоне, нужно добавить ключ `-d`. 

Если контейнер был запущен в фоне, то для того, чтобы убедиться в его успешном
запуске можно выполнить команду

```bash
docker ps
```

```
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                    NAMES
0adf5f5a5077        simple-web-app      "python3 app.py"    5 seconds ago       Up 2 seconds        0.0.0.0:5000->5000/tcp   objective_montalcini
```

которая покажет все запущенные контейнеры. Если контейнер запущен, можно 
посмотреть его логи при помощи:

```bash
docker logs -f 0adf5f5a5077
```

Вместо 0adf5f5a5077 нужно подставить id контейнера из вывода команды 
`docker ps`.

После того как мы убедились, что контейнер с нашим приложением успешно запущен,
можно открыть наше приложение в [браузере](http://0.0.0.0:5000).

После окончания работы контейнер с приложением можно будет остановить командой

```bash
docker stop 0adf5f5a5077
```

А если контейнер и образ более не нужны, то их можно удалить следующими 
командами

```bash
# Удаление контейнера
docker rm 0adf5f5a5077
# Удаление образа
docker rmi 39e2e3bc092c
```

Полезные ссылки:

- [Docker: build и пример Dockerfile](https://rtfm.co.ua/docker-build/) - заметка
  основана на данной статье
- [Погружаемся в Docker: Dockerfile и коммуникация между контейнерами](https://habr.com/ru/company/infobox/blog/240623/)



<a name='docker-compose'></a>
## docker-compose


<a name='Применение-DRY-к-docker-compose.yml'></a>
### Применение DRY к docker-compose.yml

docker-compose это отличная утилита, которая позволяет управлять запуском 
группы контейнеров. Довольно часто описание нескольких контейнеров очень 
похожее и из-за этого docker-compose.yml содержит много дублирующегося кода, 
который тяжело поддерживать. К счатью, данную проблему можно решить при помощи 
aliases и extension fields.

Формат YAML позволяет создавать якоря и алиасы. С помощью якоря можно 
определить элемент в документе YAML, а затем ссылаться на этот элемент 
(используя алиас) позже в том же документе. Якорь можно обозначить с помощью
символа &, алиас - с помощью символа *. Ниже приведен пример YAML-файла с 
якорем и алиасом: 

```docker-compose
base: &base
  name: Everyone has same name

foo:
  <<: *base
  age: 10

bar:
  <<: *base
  age: 20
```

После прочтения файла парсером YAML результат будет следующим:

```docker-compose
foo:
  name: Everyone has same name
  age: 10

bar:
  name: Everyone has same name
  age: 20
```

Использование якорей и алиасов “в чистом” виде в конфигурационных файлах 
docker-compose.yml ранее было несколько неудобным и неочевидным, однако 
начиная с версии 3.4 добавлена поддержка расширенных полей (или полей р
асширений - extension fields). 

Теперь любой ключ верхнего уровня, начинающийся с `x-` в файле 
docker-compose.yml, будет проигнорирован утилитой docker-compose и самим Docker
Engine. Такие расширения можно использовать для определения части сервиса, 
содержащей только общие параметры.

Рассмотрим описанное выше на примере. Ниже представлено содержимое 
среднестатистического docker-compose.yml файла, который описывает запуск 2 
приложений: 
 
```docker-compose
version: "2.1"

services:
  app1:
    restart: on-failure
    image: python:3.7.4-alpine
    env_file:
      - .env
    environment:
      - FOO=0
    command: python3 -c "print('Hello from app1')"

  app2:
    restart: on-failure
    image: python:3.7.4-alpine
    env_file:
      - .env
    environment:
      - BAR=1
    command: python3 -c "print('Hello from app2')"
```

Как можно заметить, часть конфигурации идентична для обоих приложений. Давайте 
избавимся от дублирования при помощи aliases и extension fields.

```docker-compose
version: "2.1"

x-app-base: &app-base
  restart: on-failure
  image: python:3.7.4-alpine
  env_file:
    - .env

services:
  app1:
    <<: *app-base
    environment:
      - FOO=0
    command: python3 -c "print('Hello from app1')"

  app2:
    <<: *app-base
    environment:
      - BAR=1
    command: python3 -c "print('Hello from app2')"
      https_proxy: $https_proxy
```

P.S. Для того, чтобы проверить не был ли нарушен синтаксис, можно использовать
`docker-compose config`.

Полезные ссылки:

- [Применение DRY к docker-compose.yml](https://ealebed.github.io/posts/2018/%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5-dry-%D0%BA-docker-compose.yml/)


<a name='Работа-с-секретами'></a>
### Работа с секретами

Проброс в контейнер контейнер секретов, которые будут использоваться во время 
работы приложения [How to use docker secrets without a swarm cluster?](https://serverfault.com/questions/871090/how-to-use-docker-secrets-without-a-swarm-cluster/)

Работа с секретами на этапе сборки образа более проблематичная задача. Сейчас
01.08.2019 ее можно решить только используя различные костыли. К счатью разработчики docker
знают об этой проблеме и работают над ее исправлением. Предлогаемое решение пока 
находится в эксперементальной ветке и пока поддерживается только на уровене 
Dockerfile (docker-compose не умеет с этим работать).

Ссылки описывающие как эксперементальное решение:

- [Build secrets and SSH forwarding in Docker 18.09 - medium](https://medium.com/@tonistiigi/build-secrets-and-ssh-forwarding-in-docker-18-09-ae8161d066)
- [Build Enhancements for Docker - docs.docker](https://docs.docker.com/develop/develop-images/build_enhancements/)
- [Support for docker build --secret for build-time docker secrets. #6358](https://github.com/docker/compose/issues/6358)

